{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b275f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snownlp in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (0.12.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\chan\\anaconda3\\lib\\site-packages (from langid) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0rc1 in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from googletrans==4.0.0rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\chan\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2022.12.7)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2023.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\chan\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.2.0)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (2.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\chan\\appdata\\roaming\\python\\python310\\site-packages (0.7.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install snownlp\n",
    "! pip install langid\n",
    "! pip install googletrans==4.0.0rc1\n",
    "! pip install emoji\n",
    "! pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b81fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji\n",
    "from spellchecker import SpellChecker\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90aecd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NLP dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a638c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text to English\n",
    "def translate_text_function(text):\n",
    "\n",
    "    def translate_to_english(text):\n",
    "        translator = Translator()\n",
    "        translation = translator.translate(text, src='ms', dest='en')\n",
    "        return translation.text\n",
    "    # def auto_translate(text):\n",
    "        #translator = Translator()\n",
    "        #translation = translator.translate(text, dest='en')\n",
    "        #\n",
    "        return translation.text\n",
    "    auto_translated_text = auto_translate(text)\n",
    "    malay_translated_text = translate_to_english(auto_translated_text)\n",
    "    translated_sentence = f\"{malay_translated_text}\"\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00092c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the 'Review' column to English and add the translations to a new column 'Translated_Review'\n",
    "df['Translated_Review'] = df['Review'].apply(translate_text_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a306dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The item has arrived.</td>\n",
       "      <td>the item has arrived.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Price Good Product Quality Good Job Good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place ... the case is bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery even from China.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china.7 days to arrive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Label  \\\n",
       "0  Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1  Fast penghantaran and good service good respon...  Positive   \n",
       "2  Good price good product quality good job good ...  Positive   \n",
       "3  penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4  Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "\n",
       "                                   Translated_Review  \\\n",
       "0                              The item has arrived.   \n",
       "1  Fast delivery and good service good response f...   \n",
       "2  Good Price Good Product Quality Good Job Good ...   \n",
       "3  Waiting that is in a place ... the case is bea...   \n",
       "4  Fast delivery even from China.7 days to arrive...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0                              the item has arrived.  \n",
       "1  fast delivery and good service good response f...  \n",
       "2  good price good product quality good job good ...  \n",
       "3  waiting that is in a place ... the case is bea...  \n",
       "4  fast delivery even from china.7 days to arrive...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Lowercase\"] = df[\"Translated_Review\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d345ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b666260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>clearpunc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The item has arrived.</td>\n",
       "      <td>the item has arrived.</td>\n",
       "      <td>the item has arrived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Price Good Product Quality Good Job Good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place  the case is beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery even from China.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china7 days to arriveb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Label  \\\n",
       "0  Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1  Fast penghantaran and good service good respon...  Positive   \n",
       "2  Good price good product quality good job good ...  Positive   \n",
       "3  penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4  Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "\n",
       "                                   Translated_Review  \\\n",
       "0                              The item has arrived.   \n",
       "1  Fast delivery and good service good response f...   \n",
       "2  Good Price Good Product Quality Good Job Good ...   \n",
       "3  Waiting that is in a place ... the case is bea...   \n",
       "4  Fast delivery even from China.7 days to arrive...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0                              the item has arrived.   \n",
       "1  fast delivery and good service good response f...   \n",
       "2  good price good product quality good job good ...   \n",
       "3  waiting that is in a place ... the case is bea...   \n",
       "4  fast delivery even from china.7 days to arrive...   \n",
       "\n",
       "                                           clearpunc  \n",
       "0                               the item has arrived  \n",
       "1  fast delivery and good service good response f...  \n",
       "2  good price good product quality good job good ...  \n",
       "3  waiting that is in a place  the case is beauti...  \n",
       "4  fast delivery even from china7 days to arriveb...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"clearpunc\"] = df[\"Lowercase\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a6f88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>clearpunc</th>\n",
       "      <th>clearstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The item has arrived.</td>\n",
       "      <td>the item has arrived.</td>\n",
       "      <td>the item has arrived</td>\n",
       "      <td>item arrived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Price Good Product Quality Good Job Good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place  the case is beauti...</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery even from China.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china7 days to arriveb...</td>\n",
       "      <td>fast delivery even china7 days arrivebeautiful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Label  \\\n",
       "0  Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1  Fast penghantaran and good service good respon...  Positive   \n",
       "2  Good price good product quality good job good ...  Positive   \n",
       "3  penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4  Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "\n",
       "                                   Translated_Review  \\\n",
       "0                              The item has arrived.   \n",
       "1  Fast delivery and good service good response f...   \n",
       "2  Good Price Good Product Quality Good Job Good ...   \n",
       "3  Waiting that is in a place ... the case is bea...   \n",
       "4  Fast delivery even from China.7 days to arrive...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0                              the item has arrived.   \n",
       "1  fast delivery and good service good response f...   \n",
       "2  good price good product quality good job good ...   \n",
       "3  waiting that is in a place ... the case is bea...   \n",
       "4  fast delivery even from china.7 days to arrive...   \n",
       "\n",
       "                                           clearpunc  \\\n",
       "0                               the item has arrived   \n",
       "1  fast delivery and good service good response f...   \n",
       "2  good price good product quality good job good ...   \n",
       "3  waiting that is in a place  the case is beauti...   \n",
       "4  fast delivery even from china7 days to arriveb...   \n",
       "\n",
       "                                           clearstop  \n",
       "0                                       item arrived  \n",
       "1  fast delivery good service good response selle...  \n",
       "2  good price good product quality good job good ...  \n",
       "3           waiting place case beautiful comfortable  \n",
       "4  fast delivery even china7 days arrivebeautiful...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"clearstop\"] = df[\"clearpunc\"].apply(lambda text: remove_stopwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ebc160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>clearpunc</th>\n",
       "      <th>clearstop</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The item has arrived.</td>\n",
       "      <td>the item has arrived.</td>\n",
       "      <td>the item has arrived</td>\n",
       "      <td>item arrived</td>\n",
       "      <td>item arrived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Price Good Product Quality Good Job Good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place  the case is beauti...</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery even from China.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china7 days to arriveb...</td>\n",
       "      <td>fast delivery even china7 days arrivebeautiful...</td>\n",
       "      <td>fast delivery even china7 day arrivebeautiful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated i like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated i like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated like item fast delivery go...</td>\n",
       "      <td>sorry pic unrelated like item fast delivery go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>penghantaran agak lambat sbb dari china...very...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Delivery is a bit slow from China ... Very Dis...</td>\n",
       "      <td>delivery is a bit slow from china ... very dis...</td>\n",
       "      <td>delivery is a bit slow from china  very disapp...</td>\n",
       "      <td>delivery bit slow china disappointing</td>\n",
       "      <td>delivery bit slow china disappointing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Recommended Seller, Fast Delivery and Descript...</td>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>recommended seller fast delivery and descripti...</td>\n",
       "      <td>recommended seller fast delivery description i...</td>\n",
       "      <td>recommended seller fast delivery description i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>very easy to broken, sakit hati</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Very Easy to Broken, Hurt</td>\n",
       "      <td>very easy to broken, hurt</td>\n",
       "      <td>very easy to broken hurt</td>\n",
       "      <td>easy broken hurt</td>\n",
       "      <td>easy broken hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2 weeks alr wear out, sakit hati, mahal ni..</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2 weeks alr wear out, pain, dear ni ..</td>\n",
       "      <td>2 weeks alr wear out, pain, dear ni ..</td>\n",
       "      <td>2 weeks alr wear out pain dear ni</td>\n",
       "      <td>2 weeks alr wear pain dear ni</td>\n",
       "      <td>2 week alr wear pain dear ni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review     Label  \\\n",
       "0    Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1    Fast penghantaran and good service good respon...  Positive   \n",
       "2    Good price good product quality good job good ...  Positive   \n",
       "3    penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4    Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "..                                                 ...       ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...  Positive   \n",
       "130  penghantaran agak lambat sbb dari china...very...  Negative   \n",
       "131  recommended seller, fast delivery and descript...  Positive   \n",
       "132                    very easy to broken, sakit hati  Negative   \n",
       "133       2 weeks alr wear out, sakit hati, mahal ni..  Negative   \n",
       "\n",
       "                                     Translated_Review  \\\n",
       "0                                The item has arrived.   \n",
       "1    Fast delivery and good service good response f...   \n",
       "2    Good Price Good Product Quality Good Job Good ...   \n",
       "3    Waiting that is in a place ... the case is bea...   \n",
       "4    Fast delivery even from China.7 days to arrive...   \n",
       "..                                                 ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...   \n",
       "130  Delivery is a bit slow from China ... Very Dis...   \n",
       "131  Recommended Seller, Fast Delivery and Descript...   \n",
       "132                          Very Easy to Broken, Hurt   \n",
       "133             2 weeks alr wear out, pain, dear ni ..   \n",
       "\n",
       "                                             Lowercase  \\\n",
       "0                                the item has arrived.   \n",
       "1    fast delivery and good service good response f...   \n",
       "2    good price good product quality good job good ...   \n",
       "3    waiting that is in a place ... the case is bea...   \n",
       "4    fast delivery even from china.7 days to arrive...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated i like this item fast deli...   \n",
       "130  delivery is a bit slow from china ... very dis...   \n",
       "131  recommended seller, fast delivery and descript...   \n",
       "132                          very easy to broken, hurt   \n",
       "133             2 weeks alr wear out, pain, dear ni ..   \n",
       "\n",
       "                                             clearpunc  \\\n",
       "0                                 the item has arrived   \n",
       "1    fast delivery and good service good response f...   \n",
       "2    good price good product quality good job good ...   \n",
       "3    waiting that is in a place  the case is beauti...   \n",
       "4    fast delivery even from china7 days to arriveb...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated i like this item fast deli...   \n",
       "130  delivery is a bit slow from china  very disapp...   \n",
       "131  recommended seller fast delivery and descripti...   \n",
       "132                           very easy to broken hurt   \n",
       "133                 2 weeks alr wear out pain dear ni    \n",
       "\n",
       "                                             clearstop  \\\n",
       "0                                         item arrived   \n",
       "1    fast delivery good service good response selle...   \n",
       "2    good price good product quality good job good ...   \n",
       "3             waiting place case beautiful comfortable   \n",
       "4    fast delivery even china7 days arrivebeautiful...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated like item fast delivery go...   \n",
       "130              delivery bit slow china disappointing   \n",
       "131  recommended seller fast delivery description i...   \n",
       "132                                   easy broken hurt   \n",
       "133                      2 weeks alr wear pain dear ni   \n",
       "\n",
       "                                            lemmatized  \n",
       "0                                         item arrived  \n",
       "1    fast delivery good service good response selle...  \n",
       "2    good price good product quality good job good ...  \n",
       "3             waiting place case beautiful comfortable  \n",
       "4    fast delivery even china7 day arrivebeautiful ...  \n",
       "..                                                 ...  \n",
       "129  sorry pic unrelated like item fast delivery go...  \n",
       "130              delivery bit slow china disappointing  \n",
       "131  recommended seller fast delivery description i...  \n",
       "132                                   easy broken hurt  \n",
       "133                       2 week alr wear pain dear ni  \n",
       "\n",
       "[134 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df[\"lemmatized\"] = df[\"clearstop\"].apply(lambda text: lemmatize_words(text))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c11483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>clearpunc</th>\n",
       "      <th>clearstop</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The item has arrived.</td>\n",
       "      <td>the item has arrived.</td>\n",
       "      <td>the item has arrived</td>\n",
       "      <td>item arrived</td>\n",
       "      <td>item arrived</td>\n",
       "      <td>[item, arrived]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "      <td>[fast, delivery, good, service, good, response...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Price Good Product Quality Good Job Good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>[good, price, good, product, quality, good, jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place  the case is beauti...</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "      <td>[waiting, place, case, beautiful, comfortable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery even from China.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china7 days to arriveb...</td>\n",
       "      <td>fast delivery even china7 days arrivebeautiful...</td>\n",
       "      <td>fast delivery even china7 day arrivebeautiful ...</td>\n",
       "      <td>[fast, delivery, even, china7, day, arrivebeau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated i like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated i like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated like item fast delivery go...</td>\n",
       "      <td>sorry pic unrelated like item fast delivery go...</td>\n",
       "      <td>[sorry, pic, unrelated, like, item, fast, deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>penghantaran agak lambat sbb dari china...very...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Delivery is a bit slow from China ... Very Dis...</td>\n",
       "      <td>delivery is a bit slow from china ... very dis...</td>\n",
       "      <td>delivery is a bit slow from china  very disapp...</td>\n",
       "      <td>delivery bit slow china disappointing</td>\n",
       "      <td>delivery bit slow china disappointing</td>\n",
       "      <td>[delivery, bit, slow, china, disappointing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Recommended Seller, Fast Delivery and Descript...</td>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>recommended seller fast delivery and descripti...</td>\n",
       "      <td>recommended seller fast delivery description i...</td>\n",
       "      <td>recommended seller fast delivery description i...</td>\n",
       "      <td>[recommended, seller, fast, delivery, descript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>very easy to broken, sakit hati</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Very Easy to Broken, Hurt</td>\n",
       "      <td>very easy to broken, hurt</td>\n",
       "      <td>very easy to broken hurt</td>\n",
       "      <td>easy broken hurt</td>\n",
       "      <td>easy broken hurt</td>\n",
       "      <td>[easy, broken, hurt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2 weeks alr wear out, sakit hati, mahal ni..</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2 weeks alr wear out, pain, dear ni ..</td>\n",
       "      <td>2 weeks alr wear out, pain, dear ni ..</td>\n",
       "      <td>2 weeks alr wear out pain dear ni</td>\n",
       "      <td>2 weeks alr wear pain dear ni</td>\n",
       "      <td>2 week alr wear pain dear ni</td>\n",
       "      <td>[2, week, alr, wear, pain, dear, ni]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review     Label  \\\n",
       "0    Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1    Fast penghantaran and good service good respon...  Positive   \n",
       "2    Good price good product quality good job good ...  Positive   \n",
       "3    penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4    Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "..                                                 ...       ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...  Positive   \n",
       "130  penghantaran agak lambat sbb dari china...very...  Negative   \n",
       "131  recommended seller, fast delivery and descript...  Positive   \n",
       "132                    very easy to broken, sakit hati  Negative   \n",
       "133       2 weeks alr wear out, sakit hati, mahal ni..  Negative   \n",
       "\n",
       "                                     Translated_Review  \\\n",
       "0                                The item has arrived.   \n",
       "1    Fast delivery and good service good response f...   \n",
       "2    Good Price Good Product Quality Good Job Good ...   \n",
       "3    Waiting that is in a place ... the case is bea...   \n",
       "4    Fast delivery even from China.7 days to arrive...   \n",
       "..                                                 ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...   \n",
       "130  Delivery is a bit slow from China ... Very Dis...   \n",
       "131  Recommended Seller, Fast Delivery and Descript...   \n",
       "132                          Very Easy to Broken, Hurt   \n",
       "133             2 weeks alr wear out, pain, dear ni ..   \n",
       "\n",
       "                                             Lowercase  \\\n",
       "0                                the item has arrived.   \n",
       "1    fast delivery and good service good response f...   \n",
       "2    good price good product quality good job good ...   \n",
       "3    waiting that is in a place ... the case is bea...   \n",
       "4    fast delivery even from china.7 days to arrive...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated i like this item fast deli...   \n",
       "130  delivery is a bit slow from china ... very dis...   \n",
       "131  recommended seller, fast delivery and descript...   \n",
       "132                          very easy to broken, hurt   \n",
       "133             2 weeks alr wear out, pain, dear ni ..   \n",
       "\n",
       "                                             clearpunc  \\\n",
       "0                                 the item has arrived   \n",
       "1    fast delivery and good service good response f...   \n",
       "2    good price good product quality good job good ...   \n",
       "3    waiting that is in a place  the case is beauti...   \n",
       "4    fast delivery even from china7 days to arriveb...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated i like this item fast deli...   \n",
       "130  delivery is a bit slow from china  very disapp...   \n",
       "131  recommended seller fast delivery and descripti...   \n",
       "132                           very easy to broken hurt   \n",
       "133                 2 weeks alr wear out pain dear ni    \n",
       "\n",
       "                                             clearstop  \\\n",
       "0                                         item arrived   \n",
       "1    fast delivery good service good response selle...   \n",
       "2    good price good product quality good job good ...   \n",
       "3             waiting place case beautiful comfortable   \n",
       "4    fast delivery even china7 days arrivebeautiful...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated like item fast delivery go...   \n",
       "130              delivery bit slow china disappointing   \n",
       "131  recommended seller fast delivery description i...   \n",
       "132                                   easy broken hurt   \n",
       "133                      2 weeks alr wear pain dear ni   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "0                                         item arrived   \n",
       "1    fast delivery good service good response selle...   \n",
       "2    good price good product quality good job good ...   \n",
       "3             waiting place case beautiful comfortable   \n",
       "4    fast delivery even china7 day arrivebeautiful ...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated like item fast delivery go...   \n",
       "130              delivery bit slow china disappointing   \n",
       "131  recommended seller fast delivery description i...   \n",
       "132                                   easy broken hurt   \n",
       "133                       2 week alr wear pain dear ni   \n",
       "\n",
       "                                             Tokenized  \n",
       "0                                      [item, arrived]  \n",
       "1    [fast, delivery, good, service, good, response...  \n",
       "2    [good, price, good, product, quality, good, jo...  \n",
       "3       [waiting, place, case, beautiful, comfortable]  \n",
       "4    [fast, delivery, even, china7, day, arrivebeau...  \n",
       "..                                                 ...  \n",
       "129  [sorry, pic, unrelated, like, item, fast, deli...  \n",
       "130        [delivery, bit, slow, china, disappointing]  \n",
       "131  [recommended, seller, fast, delivery, descript...  \n",
       "132                               [easy, broken, hurt]  \n",
       "133               [2, week, alr, wear, pain, dear, ni]  \n",
       "\n",
       "[134 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_lower(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convert tokens to lowercase\n",
    "    tokens_lower = [token.lower() for token in tokens]\n",
    "    return tokens_lower\n",
    "# Apply the tokenization function to the 'Translated_Review' column\n",
    "df['Tokenized'] = df['lemmatized'].apply(tokenize_lower)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bcd89c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>clearpunc</th>\n",
       "      <th>clearstop</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Corrected_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The item has arrived.</td>\n",
       "      <td>the item has arrived.</td>\n",
       "      <td>the item has arrived</td>\n",
       "      <td>item arrived</td>\n",
       "      <td>item arrived</td>\n",
       "      <td>[item, arrived]</td>\n",
       "      <td>[item, arrived]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery and good service good response f...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "      <td>fast delivery good service good response selle...</td>\n",
       "      <td>[fast, delivery, good, service, good, response...</td>\n",
       "      <td>[fast, delivery, good, service, good, response...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Price Good Product Quality Good Job Good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>good price good product quality good job good ...</td>\n",
       "      <td>[good, price, good, product, quality, good, jo...</td>\n",
       "      <td>[good, price, good, product, quality, good, jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place ... the case is bea...</td>\n",
       "      <td>waiting that is in a place  the case is beauti...</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "      <td>waiting place case beautiful comfortable</td>\n",
       "      <td>[waiting, place, case, beautiful, comfortable]</td>\n",
       "      <td>[waiting, place, case, beautiful, comfortable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast delivery even from China.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china.7 days to arrive...</td>\n",
       "      <td>fast delivery even from china7 days to arriveb...</td>\n",
       "      <td>fast delivery even china7 days arrivebeautiful...</td>\n",
       "      <td>fast delivery even china7 day arrivebeautiful ...</td>\n",
       "      <td>[fast, delivery, even, china7, day, arrivebeau...</td>\n",
       "      <td>[fast, delivery, even, china, day, None, None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated i like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated i like this item fast deli...</td>\n",
       "      <td>sorry pic unrelated like item fast delivery go...</td>\n",
       "      <td>sorry pic unrelated like item fast delivery go...</td>\n",
       "      <td>[sorry, pic, unrelated, like, item, fast, deli...</td>\n",
       "      <td>[sorry, pic, unrelated, like, item, fast, deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>penghantaran agak lambat sbb dari china...very...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Delivery is a bit slow from China ... Very Dis...</td>\n",
       "      <td>delivery is a bit slow from china ... very dis...</td>\n",
       "      <td>delivery is a bit slow from china  very disapp...</td>\n",
       "      <td>delivery bit slow china disappointing</td>\n",
       "      <td>delivery bit slow china disappointing</td>\n",
       "      <td>[delivery, bit, slow, china, disappointing]</td>\n",
       "      <td>[delivery, bit, slow, china, disappointing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Recommended Seller, Fast Delivery and Descript...</td>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>recommended seller fast delivery and descripti...</td>\n",
       "      <td>recommended seller fast delivery description i...</td>\n",
       "      <td>recommended seller fast delivery description i...</td>\n",
       "      <td>[recommended, seller, fast, delivery, descript...</td>\n",
       "      <td>[recommended, seller, fast, delivery, descript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>very easy to broken, sakit hati</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Very Easy to Broken, Hurt</td>\n",
       "      <td>very easy to broken, hurt</td>\n",
       "      <td>very easy to broken hurt</td>\n",
       "      <td>easy broken hurt</td>\n",
       "      <td>easy broken hurt</td>\n",
       "      <td>[easy, broken, hurt]</td>\n",
       "      <td>[easy, broken, hurt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2 weeks alr wear out, sakit hati, mahal ni..</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2 weeks alr wear out, pain, dear ni ..</td>\n",
       "      <td>2 weeks alr wear out, pain, dear ni ..</td>\n",
       "      <td>2 weeks alr wear out pain dear ni</td>\n",
       "      <td>2 weeks alr wear pain dear ni</td>\n",
       "      <td>2 week alr wear pain dear ni</td>\n",
       "      <td>[2, week, alr, wear, pain, dear, ni]</td>\n",
       "      <td>[2, week, alr, wear, pain, dear, ni]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review     Label  \\\n",
       "0    Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1    Fast penghantaran and good service good respon...  Positive   \n",
       "2    Good price good product quality good job good ...  Positive   \n",
       "3    penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4    Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "..                                                 ...       ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...  Positive   \n",
       "130  penghantaran agak lambat sbb dari china...very...  Negative   \n",
       "131  recommended seller, fast delivery and descript...  Positive   \n",
       "132                    very easy to broken, sakit hati  Negative   \n",
       "133       2 weeks alr wear out, sakit hati, mahal ni..  Negative   \n",
       "\n",
       "                                     Translated_Review  \\\n",
       "0                                The item has arrived.   \n",
       "1    Fast delivery and good service good response f...   \n",
       "2    Good Price Good Product Quality Good Job Good ...   \n",
       "3    Waiting that is in a place ... the case is bea...   \n",
       "4    Fast delivery even from China.7 days to arrive...   \n",
       "..                                                 ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...   \n",
       "130  Delivery is a bit slow from China ... Very Dis...   \n",
       "131  Recommended Seller, Fast Delivery and Descript...   \n",
       "132                          Very Easy to Broken, Hurt   \n",
       "133             2 weeks alr wear out, pain, dear ni ..   \n",
       "\n",
       "                                             Lowercase  \\\n",
       "0                                the item has arrived.   \n",
       "1    fast delivery and good service good response f...   \n",
       "2    good price good product quality good job good ...   \n",
       "3    waiting that is in a place ... the case is bea...   \n",
       "4    fast delivery even from china.7 days to arrive...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated i like this item fast deli...   \n",
       "130  delivery is a bit slow from china ... very dis...   \n",
       "131  recommended seller, fast delivery and descript...   \n",
       "132                          very easy to broken, hurt   \n",
       "133             2 weeks alr wear out, pain, dear ni ..   \n",
       "\n",
       "                                             clearpunc  \\\n",
       "0                                 the item has arrived   \n",
       "1    fast delivery and good service good response f...   \n",
       "2    good price good product quality good job good ...   \n",
       "3    waiting that is in a place  the case is beauti...   \n",
       "4    fast delivery even from china7 days to arriveb...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated i like this item fast deli...   \n",
       "130  delivery is a bit slow from china  very disapp...   \n",
       "131  recommended seller fast delivery and descripti...   \n",
       "132                           very easy to broken hurt   \n",
       "133                 2 weeks alr wear out pain dear ni    \n",
       "\n",
       "                                             clearstop  \\\n",
       "0                                         item arrived   \n",
       "1    fast delivery good service good response selle...   \n",
       "2    good price good product quality good job good ...   \n",
       "3             waiting place case beautiful comfortable   \n",
       "4    fast delivery even china7 days arrivebeautiful...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated like item fast delivery go...   \n",
       "130              delivery bit slow china disappointing   \n",
       "131  recommended seller fast delivery description i...   \n",
       "132                                   easy broken hurt   \n",
       "133                      2 weeks alr wear pain dear ni   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "0                                         item arrived   \n",
       "1    fast delivery good service good response selle...   \n",
       "2    good price good product quality good job good ...   \n",
       "3             waiting place case beautiful comfortable   \n",
       "4    fast delivery even china7 day arrivebeautiful ...   \n",
       "..                                                 ...   \n",
       "129  sorry pic unrelated like item fast delivery go...   \n",
       "130              delivery bit slow china disappointing   \n",
       "131  recommended seller fast delivery description i...   \n",
       "132                                   easy broken hurt   \n",
       "133                       2 week alr wear pain dear ni   \n",
       "\n",
       "                                             Tokenized  \\\n",
       "0                                      [item, arrived]   \n",
       "1    [fast, delivery, good, service, good, response...   \n",
       "2    [good, price, good, product, quality, good, jo...   \n",
       "3       [waiting, place, case, beautiful, comfortable]   \n",
       "4    [fast, delivery, even, china7, day, arrivebeau...   \n",
       "..                                                 ...   \n",
       "129  [sorry, pic, unrelated, like, item, fast, deli...   \n",
       "130        [delivery, bit, slow, china, disappointing]   \n",
       "131  [recommended, seller, fast, delivery, descript...   \n",
       "132                               [easy, broken, hurt]   \n",
       "133               [2, week, alr, wear, pain, dear, ni]   \n",
       "\n",
       "                                      Corrected_Tokens  \n",
       "0                                      [item, arrived]  \n",
       "1    [fast, delivery, good, service, good, response...  \n",
       "2    [good, price, good, product, quality, good, jo...  \n",
       "3       [waiting, place, case, beautiful, comfortable]  \n",
       "4    [fast, delivery, even, china, day, None, None,...  \n",
       "..                                                 ...  \n",
       "129  [sorry, pic, unrelated, like, item, fast, deli...  \n",
       "130        [delivery, bit, slow, china, disappointing]  \n",
       "131  [recommended, seller, fast, delivery, descript...  \n",
       "132                               [easy, broken, hurt]  \n",
       "133               [2, week, alr, wear, pain, dear, ni]  \n",
       "\n",
       "[134 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "# Function to check if a token contains emoji characters\n",
    "def contains_emoji(token):\n",
    "    return any(char in emoji.EMOJI_DATA for char in token)\n",
    "\n",
    "# Function to correct tokens using SpellChecker, excluding emojis\n",
    "def correct_spelling(tokens):\n",
    "    corrected_tokens = []\n",
    "    spell_checker = SpellChecker()\n",
    "\n",
    "    for token in tokens:\n",
    "        # Check if the token is an emoji\n",
    "        if contains_emoji(token):\n",
    "            # Skip emojis by not adding them to the corrected tokens\n",
    "            continue\n",
    "        else:\n",
    "            # Spell check the token\n",
    "            corrected_tokens.append(spell_checker.correction(token))\n",
    "    return corrected_tokens\n",
    "\n",
    "# Apply the correction function to the 'Tokenized_Lowercase' column\n",
    "df['Corrected_Tokens'] = df['Tokenized'].apply(correct_spelling)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "482f1c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>Corrected_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barang sudah sampai.tp foto tak Ada sangkutan....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[item, arrived]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast penghantaran and good service good respon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[fast, delivery, good, service, good, response...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good price good product quality good job good ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[good, price, good, product, quality, good, jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penantian yang berbaloi..kasut yang beautiful ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[waiting, place, case, beautiful, comfortable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penghantaran cepat walaupun dari China. 7 hari...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[fast, delivery, even, china, day, None, None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Sorry pic unrelated I like this item fast deli...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[sorry, pic, unrelated, like, item, fast, deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>penghantaran agak lambat sbb dari china...very...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[delivery, bit, slow, china, disappointing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>recommended seller, fast delivery and descript...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[recommended, seller, fast, delivery, descript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>very easy to broken, sakit hati</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[easy, broken, hurt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2 weeks alr wear out, sakit hati, mahal ni..</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[2, week, alr, wear, pain, dear, ni]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review     Label  \\\n",
       "0    Barang sudah sampai.tp foto tak Ada sangkutan....  Negative   \n",
       "1    Fast penghantaran and good service good respon...  Positive   \n",
       "2    Good price good product quality good job good ...  Positive   \n",
       "3    penantian yang berbaloi..kasut yang beautiful ...  Negative   \n",
       "4    Penghantaran cepat walaupun dari China. 7 hari...  Positive   \n",
       "..                                                 ...       ...   \n",
       "129  Sorry pic unrelated I like this item fast deli...  Positive   \n",
       "130  penghantaran agak lambat sbb dari china...very...  Negative   \n",
       "131  recommended seller, fast delivery and descript...  Positive   \n",
       "132                    very easy to broken, sakit hati  Negative   \n",
       "133       2 weeks alr wear out, sakit hati, mahal ni..  Negative   \n",
       "\n",
       "                                      Corrected_Tokens  \n",
       "0                                      [item, arrived]  \n",
       "1    [fast, delivery, good, service, good, response...  \n",
       "2    [good, price, good, product, quality, good, jo...  \n",
       "3       [waiting, place, case, beautiful, comfortable]  \n",
       "4    [fast, delivery, even, china, day, None, None,...  \n",
       "..                                                 ...  \n",
       "129  [sorry, pic, unrelated, like, item, fast, deli...  \n",
       "130        [delivery, bit, slow, china, disappointing]  \n",
       "131  [recommended, seller, fast, delivery, descript...  \n",
       "132                               [easy, broken, hurt]  \n",
       "133               [2, week, alr, wear, pain, dear, ni]  \n",
       "\n",
       "[134 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Done preprocessed\n",
    "columns_to_drop = ['Translated_Review', 'Lowercase', 'clearpunc', 'clearstop', 'lemmatized', 'Tokenized']\n",
    "new_df = df.drop(columns=columns_to_drop)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66857636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5925925925925926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.50      0.60         6\n",
      "     Neutral       0.86      0.46      0.60        13\n",
      "    Positive       0.44      0.88      0.58         8\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.68      0.61      0.59        27\n",
      "weighted avg       0.71      0.59      0.60        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Assuming 'Corrected_Tokens' is your preprocessed text column\n",
    "X = new_df['Corrected_Tokens'].astype(str)\n",
    "y = new_df['Label']\n",
    "\n",
    "# Sample dataset splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform the data using the selected features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a SVM classifier on the selected features\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the validation and test sets\n",
    "svm_predictions = svm_model.predict(X_test_vectorized)\n",
    "\n",
    "# print the classification report\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f'SVM Accuracy: {svm_accuracy}\\n')\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0096e433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.5185185185185185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.40      0.33      0.36         6\n",
      "     Neutral       0.71      0.38      0.50        13\n",
      "    Positive       0.47      0.88      0.61         8\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.53      0.53      0.49        27\n",
      "weighted avg       0.57      0.52      0.50        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = knn_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'KNN Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c78aa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.17      0.29         6\n",
      "     Neutral       0.00      0.00      0.00        13\n",
      "    Positive       0.31      1.00      0.47         8\n",
      "\n",
      "    accuracy                           0.33        27\n",
      "   macro avg       0.44      0.39      0.25        27\n",
      "weighted avg       0.31      0.33      0.20        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Chan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Chan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming 'Corrected_Tokens' is your preprocessed text column\n",
    "X = new_df['Corrected_Tokens'].astype(str)\n",
    "y = new_df['Label']\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nb_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Naive Bayes Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88a1f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.17      0.29         6\n",
      "     Neutral       1.00      0.46      0.63        13\n",
      "    Positive       0.40      1.00      0.57         8\n",
      "\n",
      "    accuracy                           0.56        27\n",
      "   macro avg       0.80      0.54      0.50        27\n",
      "weighted avg       0.82      0.56      0.54        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train the Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = logreg_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Logistic Regression Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90bcb607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5185185185185185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.50      0.33      0.40         6\n",
      "     Neutral       1.00      0.31      0.47        13\n",
      "    Positive       0.42      1.00      0.59         8\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.64      0.55      0.49        27\n",
      "weighted avg       0.72      0.52      0.49        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = rf_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebc69fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 4s 649ms/step - loss: 0.6452 - accuracy: 0.2500 - val_loss: 0.5588 - val_accuracy: 0.0909\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.5448 - accuracy: 0.2500 - val_loss: 0.3786 - val_accuracy: 0.0909\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3701 - accuracy: 0.2500 - val_loss: -0.0584 - val_accuracy: 0.0909\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0151 - accuracy: 0.2500 - val_loss: -1.2333 - val_accuracy: 0.0909\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: -0.8821 - accuracy: 0.2500 - val_loss: -2.1971 - val_accuracy: 0.0909\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: -1.1820 - accuracy: 0.2500 - val_loss: -2.7062 - val_accuracy: 0.0909\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -1.4730 - accuracy: 0.2500 - val_loss: -3.1136 - val_accuracy: 0.0909\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: -1.6623 - accuracy: 0.2500 - val_loss: -3.5098 - val_accuracy: 0.0909\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: -1.8700 - accuracy: 0.2500 - val_loss: -3.8805 - val_accuracy: 0.0909\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: -2.0722 - accuracy: 0.2500 - val_loss: -4.2199 - val_accuracy: 0.0909\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: -2.2125 - accuracy: 0.2500 - val_loss: -4.5306 - val_accuracy: 0.0909\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: -2.4097 - accuracy: 0.2500 - val_loss: -4.7811 - val_accuracy: 0.0909\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: -2.5078 - accuracy: 0.2500 - val_loss: -5.0118 - val_accuracy: 0.0909\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: -2.6106 - accuracy: 0.2500 - val_loss: -5.2191 - val_accuracy: 0.0909\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: -2.7227 - accuracy: 0.2500 - val_loss: -5.4002 - val_accuracy: 0.0909\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 89ms/step - loss: -2.7895 - accuracy: 0.2500 - val_loss: -5.5692 - val_accuracy: 0.0909\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 91ms/step - loss: -2.8963 - accuracy: 0.2500 - val_loss: -5.7131 - val_accuracy: 0.0909\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: -2.9728 - accuracy: 0.2500 - val_loss: -5.8486 - val_accuracy: 0.0909\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -3.0237 - accuracy: 0.2500 - val_loss: -5.9845 - val_accuracy: 0.0909\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: -3.1121 - accuracy: 0.2500 - val_loss: -6.1061 - val_accuracy: 0.0909\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 81ms/step - loss: -3.1648 - accuracy: 0.2500 - val_loss: -6.2287 - val_accuracy: 0.0909\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: -3.2358 - accuracy: 0.2500 - val_loss: -6.3473 - val_accuracy: 0.0909\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -3.2918 - accuracy: 0.2500 - val_loss: -6.4725 - val_accuracy: 0.0909\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: -3.3533 - accuracy: 0.2500 - val_loss: -6.6021 - val_accuracy: 0.0909\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 92ms/step - loss: -3.4344 - accuracy: 0.2500 - val_loss: -6.7269 - val_accuracy: 0.0909\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 73ms/step - loss: -3.4966 - accuracy: 0.2500 - val_loss: -6.8552 - val_accuracy: 0.0909\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: -3.5621 - accuracy: 0.2500 - val_loss: -6.9762 - val_accuracy: 0.0909\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 113ms/step - loss: -3.6218 - accuracy: 0.2500 - val_loss: -7.0927 - val_accuracy: 0.0909\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: -3.6836 - accuracy: 0.2500 - val_loss: -7.2053 - val_accuracy: 0.0909\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: -3.7319 - accuracy: 0.2500 - val_loss: -7.3212 - val_accuracy: 0.0909\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: -3.7978 - accuracy: 0.2500 - val_loss: -7.4315 - val_accuracy: 0.0909\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: -3.8499 - accuracy: 0.2500 - val_loss: -7.5434 - val_accuracy: 0.0909\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -3.9112 - accuracy: 0.2500 - val_loss: -7.6523 - val_accuracy: 0.0909\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: -3.9714 - accuracy: 0.2500 - val_loss: -7.7583 - val_accuracy: 0.0909\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: -4.0198 - accuracy: 0.2500 - val_loss: -7.8661 - val_accuracy: 0.0909\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: -4.0635 - accuracy: 0.2500 - val_loss: -7.9767 - val_accuracy: 0.0909\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -4.1355 - accuracy: 0.2500 - val_loss: -8.0776 - val_accuracy: 0.0909\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: -4.1764 - accuracy: 0.2500 - val_loss: -8.1842 - val_accuracy: 0.0909\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: -4.2492 - accuracy: 0.2500 - val_loss: -8.2786 - val_accuracy: 0.0909\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: -4.2781 - accuracy: 0.2500 - val_loss: -8.3850 - val_accuracy: 0.0909\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -4.3449 - accuracy: 0.2500 - val_loss: -8.4837 - val_accuracy: 0.0909\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: -4.3927 - accuracy: 0.2500 - val_loss: -8.5846 - val_accuracy: 0.0909\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: -4.4404 - accuracy: 0.2500 - val_loss: -8.6875 - val_accuracy: 0.0909\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: -4.4968 - accuracy: 0.2500 - val_loss: -8.7882 - val_accuracy: 0.0909\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: -4.5462 - accuracy: 0.2500 - val_loss: -8.8894 - val_accuracy: 0.0909\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: -4.6061 - accuracy: 0.2500 - val_loss: -8.9858 - val_accuracy: 0.0909\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: -4.6342 - accuracy: 0.2500 - val_loss: -9.0929 - val_accuracy: 0.0909\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: -4.7067 - accuracy: 0.2500 - val_loss: -9.1890 - val_accuracy: 0.0909\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: -4.7519 - accuracy: 0.2500 - val_loss: -9.2879 - val_accuracy: 0.0909\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -4.8008 - accuracy: 0.2500 - val_loss: -9.3877 - val_accuracy: 0.0909\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: -4.8563 - accuracy: 0.2500 - val_loss: -9.4846 - val_accuracy: 0.0909\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: -4.9063 - accuracy: 0.2500 - val_loss: -9.5818 - val_accuracy: 0.0909\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 92ms/step - loss: -4.9509 - accuracy: 0.2500 - val_loss: -9.6818 - val_accuracy: 0.0909\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: -5.0062 - accuracy: 0.2500 - val_loss: -9.7793 - val_accuracy: 0.0909\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: -5.0574 - accuracy: 0.2500 - val_loss: -9.8765 - val_accuracy: 0.0909\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -5.1112 - accuracy: 0.2500 - val_loss: -9.9718 - val_accuracy: 0.0909\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: -5.1643 - accuracy: 0.2500 - val_loss: -10.0652 - val_accuracy: 0.0909\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -5.2087 - accuracy: 0.2500 - val_loss: -10.1613 - val_accuracy: 0.0909\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: -5.2493 - accuracy: 0.2500 - val_loss: -10.2623 - val_accuracy: 0.0909\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -5.3012 - accuracy: 0.2500 - val_loss: -10.3620 - val_accuracy: 0.0909\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: -5.3593 - accuracy: 0.2500 - val_loss: -10.4574 - val_accuracy: 0.0909\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -5.4146 - accuracy: 0.2500 - val_loss: -10.5491 - val_accuracy: 0.0909\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: -5.4575 - accuracy: 0.2500 - val_loss: -10.6447 - val_accuracy: 0.0909\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: -5.5020 - accuracy: 0.2500 - val_loss: -10.7429 - val_accuracy: 0.0909\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: -5.5451 - accuracy: 0.2500 - val_loss: -10.8439 - val_accuracy: 0.0909\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -5.6043 - accuracy: 0.2500 - val_loss: -10.9397 - val_accuracy: 0.0909\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: -5.6493 - accuracy: 0.2500 - val_loss: -11.0377 - val_accuracy: 0.0909\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: -5.7037 - accuracy: 0.2500 - val_loss: -11.1318 - val_accuracy: 0.0909\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: -5.7407 - accuracy: 0.2500 - val_loss: -11.2314 - val_accuracy: 0.0909\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: -5.8035 - accuracy: 0.2500 - val_loss: -11.3237 - val_accuracy: 0.0909\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -5.8505 - accuracy: 0.2500 - val_loss: -11.4170 - val_accuracy: 0.0909\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -5.8966 - accuracy: 0.2500 - val_loss: -11.5114 - val_accuracy: 0.0909\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: -5.9473 - accuracy: 0.2500 - val_loss: -11.6045 - val_accuracy: 0.0909\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: -6.0007 - accuracy: 0.2500 - val_loss: -11.6951 - val_accuracy: 0.0909\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: -6.0470 - accuracy: 0.2500 - val_loss: -11.7872 - val_accuracy: 0.0909\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -6.1025 - accuracy: 0.2500 - val_loss: -11.8744 - val_accuracy: 0.0909\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: -6.1390 - accuracy: 0.2500 - val_loss: -11.9692 - val_accuracy: 0.0909\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -6.1909 - accuracy: 0.2500 - val_loss: -12.0620 - val_accuracy: 0.0909\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: -6.2381 - accuracy: 0.2500 - val_loss: -12.1556 - val_accuracy: 0.0909\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: -6.2774 - accuracy: 0.2500 - val_loss: -12.2540 - val_accuracy: 0.0909\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: -6.3369 - accuracy: 0.2500 - val_loss: -12.3465 - val_accuracy: 0.0909\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: -6.3839 - accuracy: 0.2500 - val_loss: -12.4399 - val_accuracy: 0.0909\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: -6.4312 - accuracy: 0.2500 - val_loss: -12.5342 - val_accuracy: 0.0909\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: -6.4702 - accuracy: 0.2500 - val_loss: -12.6331 - val_accuracy: 0.0909\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -6.5224 - accuracy: 0.2500 - val_loss: -12.7294 - val_accuracy: 0.0909\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: -6.5822 - accuracy: 0.2500 - val_loss: -12.8193 - val_accuracy: 0.0909\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -6.6232 - accuracy: 0.2500 - val_loss: -12.9134 - val_accuracy: 0.0909\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: -6.6855 - accuracy: 0.2500 - val_loss: -12.9977 - val_accuracy: 0.0909\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: -6.7212 - accuracy: 0.2500 - val_loss: -13.0902 - val_accuracy: 0.0909\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: -6.7537 - accuracy: 0.2500 - val_loss: -13.1900 - val_accuracy: 0.0909\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -6.8094 - accuracy: 0.2500 - val_loss: -13.2850 - val_accuracy: 0.0909\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: -6.8634 - accuracy: 0.2500 - val_loss: -13.3768 - val_accuracy: 0.0909\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -6.9021 - accuracy: 0.2500 - val_loss: -13.4727 - val_accuracy: 0.0909\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -6.9576 - accuracy: 0.2500 - val_loss: -13.5646 - val_accuracy: 0.0909\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: -7.0117 - accuracy: 0.2500 - val_loss: -13.6526 - val_accuracy: 0.0909\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: -7.0631 - accuracy: 0.2500 - val_loss: -13.7379 - val_accuracy: 0.0909\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: -7.1017 - accuracy: 0.2500 - val_loss: -13.8289 - val_accuracy: 0.0909\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: -7.1520 - accuracy: 0.2500 - val_loss: -13.9181 - val_accuracy: 0.0909\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: -7.1933 - accuracy: 0.2500 - val_loss: -14.0111 - val_accuracy: 0.0909\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: -7.2374 - accuracy: 0.2500 - val_loss: -14.1060 - val_accuracy: 0.0909\n",
      "1/1 [==============================] - 1s 607ms/step\n",
      "Accuracy: 0.48148148148148145\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.48      1.00      0.65        13\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.48        27\n",
      "   macro avg       0.16      0.33      0.22        27\n",
      "weighted avg       0.23      0.48      0.31        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Chan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Chan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Assuming 'Corrected_Tokens' is your preprocessed text column\n",
    "X = df['Corrected_Tokens'].astype(str)\n",
    "y = df['Label']\n",
    "\n",
    "# Label encoding for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization and padding\n",
    "max_words = 5000\n",
    "max_len = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Define the LSTM model\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(units=100))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = (model.predict(X_test_padded) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'LSTM Accuracy: {accuracy}\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee11011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 141ms/step - loss: 0.3177 - accuracy: 0.2604 - val_loss: -0.6515 - val_accuracy: 0.0909\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: -0.4818 - accuracy: 0.2500 - val_loss: -1.5747 - val_accuracy: 0.0909\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: -1.0460 - accuracy: 0.2500 - val_loss: -2.5251 - val_accuracy: 0.0909\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: -1.6102 - accuracy: 0.2500 - val_loss: -3.6468 - val_accuracy: 0.0909\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: -2.3020 - accuracy: 0.2500 - val_loss: -4.8438 - val_accuracy: 0.0909\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Accuracy: 0.48148148148148145\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming 'Corrected_Tokens' is your preprocessed text column\n",
    "X = df['Corrected_Tokens'].astype(str)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences for uniform length\n",
    "X_train_padded = pad_sequences(X_train_sequences)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=X_train_padded.shape[1])\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=X_train_padded.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Use 1 neuron for binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the mod\n",
    "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_padded)\n",
    "predictions_binary = np.round(predictions)  # Convert probabilities to binary predictions (0 or 1)\n",
    "\n",
    "# Convert predictions to original labels\n",
    "predictions_labels = label_encoder.inverse_transform(predictions_binary.flatten().astype(int))\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions_binary)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12284035",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logistic_regression_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the pre-trained Logistic Regression model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogistic_regression_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_vectorizer.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_input\u001b[39m(text):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Translate text to English\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    577\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logistic_regression_model.pkl'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Load the pre-trained Logistic Regression model\n",
    "model = joblib.load('logistic_regression_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "def preprocess_input(text):\n",
    "    # Translate text to English\n",
    "    def translate_text_function(text):\n",
    "        translator = Translator()\n",
    "        translation = translator.translate(text, dest='en')\n",
    "        return translation.text\n",
    "\n",
    "    # Preprocess text\n",
    "    def preprocess_text(text):\n",
    "        lowercase_text = text.lower()\n",
    "        without_punctuation = \"\".join([char for char in lowercase_text if char not in string.punctuation])\n",
    "        without_stopwords = \" \".join([word for word in without_punctuation.split() if word not in stopwords.words('english')])\n",
    "        return without_stopwords\n",
    "\n",
    "    translated_text = translate_text_function(text)\n",
    "    preprocessed_text = preprocess_text(translated_text)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "def predict_sentiment(review_text):\n",
    "    # Preprocess user input\n",
    "    preprocessed_text = preprocess_input(review_text)\n",
    "\n",
    "    # Vectorize the input\n",
    "    input_vectorized = vectorizer.transform([preprocessed_text])\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = model.predict(input_vectorized)\n",
    "\n",
    "    return prediction[0]\n",
    "\n",
    "# Function to get user input and display result\n",
    "def analyze_review():\n",
    "    user_input = entry.get()\n",
    "    result = predict_sentiment(user_input)\n",
    "    result_label.config(text=f\"Sentiment: {result}\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Sentiment Analysis\")\n",
    "\n",
    "# Create an entry widget for user input\n",
    "entry = tk.Entry(window, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Create a button to trigger sentiment analysis\n",
    "analyze_button = tk.Button(window, text=\"Analyze\", command=analyze_review)\n",
    "analyze_button.pack(pady=10)\n",
    "\n",
    "# Create a label to display the result\n",
    "result_label = tk.Label(window, text=\"\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Start the GUI event loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5249221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Chan\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.433 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Label, Entry, Button, StringVar\n",
    "import jieba\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "def analyze_sentiment(user_input):\n",
    "    # Use jieba to segment Chinese text into words\n",
    "    words = jieba.cut(user_input)\n",
    "\n",
    "    # Join the segmented words into a string\n",
    "    segmented_text = \" \".join(words)\n",
    "\n",
    "    # Use SnowNLP for sentiment analysis\n",
    "    snow_nlp = SnowNLP(segmented_text)\n",
    "    sentiment_score = snow_nlp.sentiments\n",
    "\n",
    "    return sentiment_score\n",
    "\n",
    "def analyze_sentiment_wrapper():\n",
    "    # Get user input from the Entry widget\n",
    "    user_input = entry.get()\n",
    "\n",
    "    # Analyze sentiment and display the result\n",
    "    sentiment_score = analyze_sentiment(user_input)\n",
    "    result_var.set(f\"Sentiment Score: {sentiment_score:.2f}\")\n",
    "\n",
    "# Create a Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Sentiment Analysis UI\")\n",
    "\n",
    "# Create a label\n",
    "label = Label(root, text=\"Enter a sentence:\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Create an entry widget for user input\n",
    "entry = Entry(root, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Create a button to trigger sentiment analysis\n",
    "analyze_button = Button(root, text=\"Analyze Sentiment\", command=analyze_sentiment_wrapper)\n",
    "analyze_button.pack(pady=10)\n",
    "\n",
    "# Display the sentiment score\n",
    "result_var = StringVar()\n",
    "result_label = Label(root, textvariable=result_var)\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4666378",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 5 (877653158.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    def open_user_input_sentiment_program():\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 5\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Label, Button\n",
    "\n",
    "# Function to open the program for checking sentiment score of the CSV\n",
    "def open_csv_sentiment_program():\n",
    "    # Include your CSV Sentiment Analysis program code here\n",
    "    # ...\n",
    "\n",
    "# Function to open the program for checking sentiment score of user input\n",
    "def open_user_input_sentiment_program():\n",
    "    import tkinter as tk\n",
    "    from tkinter import Label, Entry, Button, StringVar\n",
    "    import jieba\n",
    "    from snownlp import SnowNLP\n",
    "\n",
    "    def analyze_sentiment(user_input):\n",
    "       # Use jieba to segment Chinese text into words\n",
    "        words = jieba.cut(user_input)\n",
    "\n",
    "        # Join the segmented words into a string\n",
    "    segmented_text = \" \".join(words)\n",
    "\n",
    "    # Use SnowNLP for sentiment analysis\n",
    "    snow_nlp = SnowNLP(segmented_text)\n",
    "    sentiment_score = snow_nlp.sentiments\n",
    "\n",
    "    return sentiment_score\n",
    "\n",
    "def analyze_sentiment_wrapper():\n",
    "    # Get user input from the Entry widget\n",
    "    user_input = entry.get()\n",
    "\n",
    "    # Analyze sentiment and display the result\n",
    "    sentiment_score = analyze_sentiment(user_input)\n",
    "    result_var.set(f\"Sentiment Score: {sentiment_score:.2f}\")\n",
    "\n",
    "# Create a Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Sentiment Analysis UI\")\n",
    "\n",
    "# Create a label\n",
    "label = Label(root, text=\"Enter a sentence:\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Create an entry widget for user input\n",
    "entry = Entry(root, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Create a button to trigger sentiment analysis\n",
    "analyze_button = Button(root, text=\"Analyze Sentiment\", command=analyze_sentiment_wrapper)\n",
    "analyze_button.pack(pady=10)\n",
    "\n",
    "# Display the sentiment score\n",
    "result_var = StringVar()\n",
    "result_label = Label(root, textvariable=result_var)\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n",
    "\n",
    "\n",
    "\n",
    "# Create a Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Sentiment Analysis Main Page\")\n",
    "\n",
    "# Display a label\n",
    "label = Label(root, text=\"Choose an option:\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Button to open the program for checking sentiment score of the CSV\n",
    "csv_button = Button(root, text=\"Check Sentiment Score of CSV\", command=open_csv_sentiment_program)\n",
    "csv_button.pack(pady=10)\n",
    "\n",
    "# Button to open the program for checking sentiment score of user input\n",
    "user_input_button = Button(root, text=\"Check Sentiment Score of User Input\", command=open_user_input_sentiment_program)\n",
    "user_input_button.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0584316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
